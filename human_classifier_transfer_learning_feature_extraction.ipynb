{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1YS_mpYGznZCVo8Zd2Ppg_Vom_QEHwS9k",
      "authorship_tag": "ABX9TyOYtz67vdmzUxqRiAU1gofd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SaketMunda/human-classifier-unsplash-dataset/blob/master/human_classifier_transfer_learning_feature_extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building Human Classifier using Transfer Learning Feature extraction\n",
        "\n",
        "This notebook is responsible for building our own transfer learning feature extraction model for human classification problem.\n",
        "\n",
        "For transfer learning, we'll take two models from [`tensorflow_hub`](https://www.tensorflow.org/hub) and visualize the performance of both the experiments using [`Tensorboard Playground`](https://www.tensorflow.org/tensorboard).  \n",
        "\n",
        "\n",
        "We're taking here only 10% of dataset from original extracted images from Unsplash, since we are using feature extraction transfer learning, and it often allows us to get great results with less data.\n",
        "\n"
      ],
      "metadata": {
        "id": "wGErJ4Y61cAh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem Definition\n",
        "\n",
        "We're working towards building pre-trained model and adding our own custom layers on top, extracting all of the underlying weights and biases learned on another dataset and use them on our own unsplash extracted images to classify whether an image contains **human** or not."
      ],
      "metadata": {
        "id": "AdMySlDo7xfN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating data loaders (preparing the data)\n",
        "\n",
        "There are couple of ways to load the data and prepare it for our network, and most commonly used is `ImageDataGenerator`, and one more `image_dataset_from_directory` function.\n",
        "\n",
        "For now let's use the basic one `ImageDataGenerator`, since we are not using a larger dataset so it'll be fine, but if we have to use a larger dataset then we should use `image_dataset_from_directory` function since it creates a `tf.Data.Dataset` object rather than a generator. \n",
        "\n",
        "Since we are dealing with predicting a class i.e binary classification problem, so I've created a dataset in that format only.\n",
        "\n",
        "Directories is in the below format for train and test dataset,\n",
        "- train/human, train/non-human\n",
        "- test/human, test/non-human\n"
      ],
      "metadata": {
        "id": "JwokenjC22lZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# setup the data inputs\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "IMG_SHAPE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# declaring constant drive paths\n",
        "drive_path = 'drive/MyDrive/Data Science/HumanClassifier/'\n",
        "train_dir = drive_path + 'photos/train/'\n",
        "test_dir = drive_path + 'photos/test/'\n",
        "\n",
        "# Instantiating ImageDataGenerator\n",
        "# rescaling since the the range of image tensors would be between 0-255\n",
        "train_datagen = ImageDataGenerator(rescale=1/255.) \n",
        "test_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "\n",
        "print('Training images:')\n",
        "train_data_10_percent = train_datagen.flow_from_directory(train_dir,\n",
        "                                                          target_size=IMG_SHAPE,\n",
        "                                                          batch_size=BATCH_SIZE,\n",
        "                                                          class_mode='binary')\n",
        "\n",
        "print('Test images:')\n",
        "test_data = test_datagen.flow_from_directory(test_dir,\n",
        "                                             target_size=IMG_SHAPE,\n",
        "                                             batch_size=BATCH_SIZE,\n",
        "                                             class_mode='binary')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQE17_cM7vAR",
        "outputId": "a61bf9eb-4f2c-4c3e-abbd-2c1fba0313aa"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training images:\n",
            "Found 350 images belonging to 2 classes.\n",
            "Test images:\n",
            "Found 350 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting Up Callbacks\n",
        "\n",
        "Before building our model, to track how is our model performing or how much further training is required for our model, and few more things we can do via `callbacks` which executes during or after training our model.\n",
        "\n",
        "Since we want to visualize the performance of two models of tensorflow_hub, and compare them, so we'll be creating a `TensorBoard` callback, which will create a dashboard for inspecting neural network parameters.\n",
        "\n",
        "The Tensorboard callback can be accessed using `tf.keras.callbacks.TensorBoard()`.\n",
        "\n",
        "It's main functionality is saving a model's training performance metrics to a specified `log_dir`.\n",
        "\n",
        "To track our modelling experiments using Tensorboard, we'll create a function which creates a tensorboard callback for us, so that each time when we fit our model, it create a new one each time.\n",
        "\n"
      ],
      "metadata": {
        "id": "thdk6ted95d5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create tensorboard callback\n",
        "import datetime\n",
        "import tensorflow\n",
        "\n",
        "def create_tensorboard_callback(dir_name, experiment_name):\n",
        "  log_dir = dir_name + \"/\" + experiment_name + \"/\" + datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
        "  tensorboard_callback = tensorflow.keras.callbacks.TensorBoard(\n",
        "      log_dir = log_dir\n",
        "  )\n",
        "  print(f'Saving Tensorboard Log files to: {log_dir}')\n",
        "  return tensorboard_callback"
      ],
      "metadata": {
        "id": "WX8-5k2iCUdY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating models using Tensorflow Hub\n",
        "\n",
        "We're going to use two models from Tensorflow Hub:\n",
        "\n",
        "- [ResNet50V2](https://arxiv.org/abs/1603.05027) : a state of art computer vision model architecture from 2016\n",
        "- [EfficientNetB0](https://arxiv.org/abs/1905.11946) : a state of art computer vision model architecture from 2019\n",
        "\n",
        "> ðŸ’¡ *The Tesla Vehicle AI processes huge doses of information in real-time. So the Computer Vision workflow runs all the tasks on a shared backbone called **ResNet-50** that has the ability to run 1000Ã—1000 images at a time*.\n",
        "\n",
        "Let's build our model using the above said models from TensorFlow Hub.\n"
      ],
      "metadata": {
        "id": "j1z2S5-DEolp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries for tensorflow and tensorflow hub\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "nkj47VzXFZl2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we'll get feature vector URLs of two common computer vision architectures, [EfficientNetB0(2019)](https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1) and [ResNetV250(2016)](https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/4) from TensorFlow Hub"
      ],
      "metadata": {
        "id": "eIsWOEdjGO2h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Resnet50V2 feature vector\n",
        "resnet_url = \"https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/4\"\n",
        "\n",
        "# EfficientNetB0 feature vector\n",
        "efficientnet_url = \"https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1\""
      ],
      "metadata": {
        "id": "oLPitpDNGiJi"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These URLs link to a saved pretrained model on Tensorflow Hub.\n",
        "\n",
        "When we use them in our model, the model will automatically get downloaded for us to use.\n",
        "\n",
        "To do this, we can use the `KerasLayer()` model inside the TensorFlow Hub library.\n",
        "\n",
        "Since we're going to be comparing two models, to save ourselves code, we'll create a function `create_model()`. This function will take a model's TensorFlow Hub URL, instantiate a Keras Sequential model with the appropriate number of output layers, compile the model and return the model."
      ],
      "metadata": {
        "id": "wL6nTsLhGtWR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(model_url):\n",
        "  \"\"\"\n",
        "  Takes a TensorFlow Hub URL and creates a Keras Sequential model with it.\n",
        "\n",
        "  Args:\n",
        "    model_url(str): A tensorflow hub feature extraction URL    \n",
        "  Returns:\n",
        "    A compiled Keras Sequential model with model_url as feature extractor layer \n",
        "    and Dense output layer with num_classes outputs.\n",
        "  \"\"\"\n",
        "\n",
        "  # Download the pretrained model and save it as Keras Layer\n",
        "  feature_extractor_layer = hub.KerasLayer(model_url, \n",
        "                                           trainable=False, # freeze the underlying patterns\n",
        "                                           name='feature_extractor_layer',\n",
        "                                           input_shape = IMG_SHAPE+(3,))\n",
        "  \n",
        "  # Create our own model\n",
        "  model = tf.keras.Sequential([\n",
        "      feature_extractor_layer, # Use feature extraction layer as the base\n",
        "      layers.Dense(1, activation='sigmoid', name='output_layer') # create our own output layer\n",
        "  ])\n",
        "\n",
        "  # compile our model\n",
        "  model.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "                optimizer='Adam',\n",
        "                metrics=['accuracy'])\n",
        "  \n",
        "  return model"
      ],
      "metadata": {
        "id": "Np78HOOxILKl"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Great ! Now we've got a function for creating a model, we'll use it to first create and compile a model using ResNet50V2 architecture as our feature extraction compiled model.\n",
        "\n",
        "Then we'll fit the model with our own training data and test data and also use the callbacks."
      ],
      "metadata": {
        "id": "m_S0kCtlKmJb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create and compile the model\n",
        "resnet_model = create_model(resnet_url)\n",
        "\n",
        "# fit the model\n",
        "resnet_history = resnet_model.fit(train_data_10_percent,\n",
        "                                  epochs=5,\n",
        "                                  steps_per_epoch=len(train_data_10_percent),\n",
        "                                  validation_data=test_data,\n",
        "                                  validation_steps=len(test_data),\n",
        "                                  callbacks=[create_tensorboard_callback(dir_name='tensorflow_hub',\n",
        "                                                                         experiment_name='resnet50v2')])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5LvWh6nLWRY",
        "outputId": "8b1c6d02-aad1-435c-9d83-74971c00d523"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Tensorboard Log files to: tensorflow_hub/resnet50v2/20221231-080820\n",
            "Epoch 1/5\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.8720 - accuracy: 0.4943 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/PIL/Image.py:2797: DecompressionBombWarning: Image size (146784000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/PIL/Image.py:2797: DecompressionBombWarning: Image size (94212096 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r11/11 [==============================] - 927s 87s/step - loss: 0.8720 - accuracy: 0.4943 - val_loss: 0.7529 - val_accuracy: 0.5514\n",
            "Epoch 2/5\n",
            "11/11 [==============================] - 259s 25s/step - loss: 0.6757 - accuracy: 0.6086 - val_loss: 0.7135 - val_accuracy: 0.6029\n",
            "Epoch 3/5\n",
            "11/11 [==============================] - 260s 25s/step - loss: 0.5863 - accuracy: 0.6914 - val_loss: 0.7187 - val_accuracy: 0.6029\n",
            "Epoch 4/5\n",
            "11/11 [==============================] - 259s 25s/step - loss: 0.5290 - accuracy: 0.7486 - val_loss: 0.7014 - val_accuracy: 0.6114\n",
            "Epoch 5/5\n",
            "11/11 [==============================] - 257s 25s/step - loss: 0.4703 - accuracy: 0.7857 - val_loss: 0.7179 - val_accuracy: 0.6057\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Not bad, but it looks like that in test data it is not performing very well compared to train data, that means model is not learning quite good.\n",
        "\n",
        "However that is not our goal, we're trying here to build a model using a pre-trained model.\n",
        "\n",
        "So let's continue our experiment.\n",
        "\n",
        "This time, taking the efficient net url for creating and fitting the model."
      ],
      "metadata": {
        "id": "jDgxchiUWliH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "efficient_model = create_model(efficientnet_url)\n",
        "\n",
        "# fit the model\n",
        "efficient_history = efficient_model.fit(train_data_10_percent,\n",
        "                                  epochs=5,\n",
        "                                  steps_per_epoch=len(train_data_10_percent),\n",
        "                                  validation_data=test_data,\n",
        "                                  validation_steps=len(test_data),\n",
        "                                  callbacks=[create_tensorboard_callback(dir_name='tensorflow_hub',\n",
        "                                                                         experiment_name='efficientnet')])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVGQKzB0XMPk",
        "outputId": "b6f8e110-5b3f-428a-d027-9976e20c6e5c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Tensorboard Log files to: tensorflow_hub/efficientnet/20221231-084830\n",
            "Epoch 1/5\n",
            "11/11 [==============================] - ETA: 0s - loss: 0.7069 - accuracy: 0.5514 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/PIL/Image.py:2797: DecompressionBombWarning: Image size (146784000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/PIL/Image.py:2797: DecompressionBombWarning: Image size (94212096 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r11/11 [==============================] - 282s 26s/step - loss: 0.7069 - accuracy: 0.5514 - val_loss: 0.6792 - val_accuracy: 0.5857\n",
            "Epoch 2/5\n",
            "11/11 [==============================] - 261s 25s/step - loss: 0.6417 - accuracy: 0.6486 - val_loss: 0.6744 - val_accuracy: 0.6029\n",
            "Epoch 3/5\n",
            "11/11 [==============================] - 262s 25s/step - loss: 0.6059 - accuracy: 0.6829 - val_loss: 0.6720 - val_accuracy: 0.6257\n",
            "Epoch 4/5\n",
            "11/11 [==============================] - 267s 25s/step - loss: 0.5736 - accuracy: 0.7314 - val_loss: 0.6734 - val_accuracy: 0.6143\n",
            "Epoch 5/5\n",
            "11/11 [==============================] - 262s 25s/step - loss: 0.5484 - accuracy: 0.7714 - val_loss: 0.6722 - val_accuracy: 0.6086\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparing Models using TensorBoard\n",
        "\n",
        "Since, we've already created a callback function to save the logs of each experiment we did for each model, we can preview those logs using TensorBoard.\n",
        "\n",
        "To visualize them, we can upload the results to [TensorBoard.dev](https://tensorboard.dev/)\n",
        "\n",
        "By uploading it to TensorBoard.dev, we can share the results to others as well.\n",
        "\n",
        "For uploading a series of TensorFlow logs to TensorBoard, we can use the following command:"
      ],
      "metadata": {
        "id": "y5gS1HrJXhKZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!tensorboard dev upload --logdir ./tensorflow_hub/ \\\n",
        "  --name \"EfficientNetB0 Vs ResNet50V2\" \\\n",
        "  --description \"Comparing two different TF Hub feature extraction models architecture using 10% of unsplash images of human and non-humans\" \\\n",
        "  --one_shot # this is to exit"
      ],
      "metadata": {
        "id": "mjuXT2kZeB_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TensorBoard experiment URL : https://tensorboard.dev/experiment/6QZoenQwQ4KHX2T42h6DMw/"
      ],
      "metadata": {
        "id": "tTpZ-7bHekXf"
      }
    }
  ]
}